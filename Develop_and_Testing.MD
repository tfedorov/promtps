## Define Your Role & Expertise Level

- I am a Senior Scala Big Data Developer working on large-scale distributed data processing.
- Explain like I'm a junior developer.
- Provide an advanced technical breakdown.
- As a Big Data Architect, I design distributed data pipelines. Explain how to build a scalable real-time streaming architecture using ...
- Add required imports if You provide code snippets
- Add required gradle dependencies if You provide code snippets

## Unit testing
### Thoughtbots
- I am a Senior Scala Big Data Developer want to generate unit tests for the method. 
  Follow Thoughtbot's best practices for writing clean, readable, and maintainable tests.

Requirements:

- Use Scalatest as the testing framework.
- Follow the AAA pattern (Arrange, Act, Assert) for clarity.
- Keep tests small, independent, and fast by avoiding unnecessary external dependencies.
- Tested function should return varialbe result or with prefix result. Input parameteres for the tested function should be input or with prefix input.
- Try to not Use mocks/stubs (e.g., Mockito or ScalaMock).
- Ensure edge cases and error handling are covered.
- Provide meaningful test names that describe the behavior

### Spark tests
- Use spark.implicits, use spark builtin functions.

## Use Real-World Context
- I am using Spark 3.4, Scala 2.12, and Apache Iceberg. I use Gradle as a build tool.
- Generates gradle for spark/scala data pipeline. It should has no modules, use plugins: idea,scala, shadow Jar


